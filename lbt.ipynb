{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(true_values, predicted_values):\n",
    "    \"\"\"Plot true vs predicted counts and loss.\"\"\"\n",
    "   \n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(true_values, predicted_values)\n",
    "\n",
    "    plt.title('Train')\n",
    "    plt.xlabel('True value')\n",
    "    plt.ylabel('Predicted value')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 3070\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from base import gpu_test\n",
    "\n",
    "device = gpu_test.get_device()\n",
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hicks\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:48: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "from lbt.search.backbone import model_search\n",
    "from lbt import architect\n",
    "from base import FCRNA\n",
    "from lbt.architect import cusloss\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "criterion_stud = torch.nn.MSELoss()\n",
    "criterion_stud = criterion_stud.cuda()\n",
    "\n",
    "\n",
    "model = model_search.Network(input_c = 3, c = 24, num_classes = 1, criterion = criterion, depth = 3, device = device)\n",
    "model = model.cuda()\n",
    "\n",
    "student  = FCRNA.FCRN_A(criterion_stud, input_filters=3, filters=64, N=2)\n",
    "student = student.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.025, momentum=0.9, weight_decay=3e-4)\n",
    "optimizer_stud =  torch.optim.SGD(student.parameters(), 0.025, momentum=0.9, weight_decay=3e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, float(epochs))\n",
    "\n",
    "architect = architect.Architect(model, student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import data_loader\n",
    "from base import train\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "data_loader = train.get_loader('cell', batch_size=1)\n",
    "data_loader_unlabeled = train.get_loader('cell', batch_size=1)\n",
    "\n",
    "train_queue = data_loader['train']\n",
    "valid_queue = data_loader['valid']\n",
    "unlabeled_queue = data_loader_unlabeled['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_queue, valid_queue, unlabeled_queue, model, student, architect, criterion, criterion_stud, optimizer, optimizer_stud, lr):\n",
    "    \n",
    "    true_values = []\n",
    "    predicted_values = []\n",
    "    \n",
    "    for image, target in tqdm(train_queue):\n",
    "        model.train()\n",
    "\n",
    "        image = Variable(image, requires_grad=False).cuda()\n",
    "        target = Variable(target, requires_grad=False).cuda()\n",
    "\n",
    "        # get a random minibatch from the search queue with replacement\n",
    "        input_search, target_search = next(iter(valid_queue))\n",
    "        input_search = Variable(input_search, requires_grad=True).cuda()\n",
    "        target_search = Variable(target_search, requires_grad=True).cuda()\n",
    "\n",
    "        # get a random minibatch from the cifar-100 queue with replacement\n",
    "        input_unlabeled, target_unlabeled = next(iter(unlabeled_queue))\n",
    "        input_unlabeled = Variable(input_unlabeled, requires_grad=True).cuda()\n",
    "        target_unlabeled = Variable(target_unlabeled, requires_grad=True).cuda()\n",
    "\n",
    "        architect.step(image, target, input_search, target_search, input_unlabeled, lr, optimizer, unrolled=True)\n",
    "        architect.step1(image, target, input_search, target_search, input_unlabeled, lr, optimizer, optimizer_stud, unrolled=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(image)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer_stud.zero_grad()\n",
    "        l1 = model(input_unlabeled)\n",
    "        logits1 = student(input_unlabeled)\n",
    "        loss1 = cusloss(logits1, l1.detach())\n",
    "\n",
    "\n",
    "        loss1.backward()\n",
    "        #nn.utils.clip_grad_norm(student.parameters(), args.grad_clip)\n",
    "        optimizer_stud.step()\n",
    "\n",
    "        optimizer_stud.zero_grad()\n",
    "        logits2 = student(image)\n",
    "        loss2 = criterion_stud(logits2, target)\n",
    "\n",
    "        loss2.backward()\n",
    "        #nn.utils.clip_grad_norm(student.parameters(), args.grad_clip)\n",
    "        optimizer_stud.step()\n",
    "        \n",
    "        for true, predicted in zip(label, logits):\n",
    "\n",
    "            true_counts = torch.sum(true).item() / 100\n",
    "            predicted_counts = torch.sum(predicted).item() / 100\n",
    "\n",
    "            # update current epoch results\n",
    "            true_values.append(true_counts)\n",
    "            predicted_values.append(predicted_counts)\n",
    "        \n",
    "        print(loss.item())\n",
    "        plot(true_values, predicted_values)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hicks\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "C:\\Users\\hicks\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:508: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff6c78cc7e84e45b05e2aba24c2303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-552760ae8f04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlabeled_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion_stud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_stud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-1c26a4e86d8a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, unlabeled_queue, model, student, architect, criterion, criterion_stud, optimizer, optimizer_stud, lr)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtarget_unlabeled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_unlabeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0marchitect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_search\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_search\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_unlabeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munrolled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0marchitect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_search\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_search\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_unlabeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_stud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munrolled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ECE\\269\\project_code\\lbt\\architect.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, input_train, target_train, input_valid, target_valid, input_unlabeled, eta, network_optimizer, unrolled)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0munrolled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backward_step_unrolled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backward_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ECE\\269\\project_code\\lbt\\architect.py\u001b[0m in \u001b[0;36m_backward_step_unrolled\u001b[1;34m(self, input_train, target_train, input_valid, target_valid, eta, network_optimizer)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_backward_step_unrolled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0munrolled_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_unrolled_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[0munrolled_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munrolled_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ECE\\269\\project_code\\lbt\\architect.py\u001b[0m in \u001b[0;36m_compute_unrolled_model\u001b[1;34m(self, input, target, eta, network_optimizer)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m       \u001b[0mmoment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mdtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_unused\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork_weight_decay\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0munrolled_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_model_from_theta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmoment\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0munrolled_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         inputs, allow_unused, accumulate_grad=False)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    \n",
    "    scheduler.step()\n",
    "    lr = scheduler.get_lr()[0]\n",
    "    \n",
    "    train(train_queue, valid_queue, unlabeled_queue, model, student, architect, criterion, criterion_stud, optimizer, optimizer_stud, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in student.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
