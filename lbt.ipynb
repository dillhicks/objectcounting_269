{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(true_values, predicted_values):\n",
    "    \"\"\"Plot true vs predicted counts and loss.\"\"\"\n",
    "   \n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(true_values, predicted_values)\n",
    "\n",
    "    plt.title('Train')\n",
    "    plt.xlabel('True value')\n",
    "    plt.ylabel('Predicted value')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 3070\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from base import gpu_test\n",
    "\n",
    "device = gpu_test.get_device()\n",
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hicks\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:48: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "from lbt.search.backbone import model_search\n",
    "from lbt import architect\n",
    "from base import FCRNA\n",
    "from lbt.architect import cusloss\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "criterion_stud = torch.nn.MSELoss()\n",
    "criterion_stud = criterion_stud.cuda()\n",
    "\n",
    "\n",
    "model = model_search.Network(input_c = 3, c = 24, num_classes = 1, criterion = criterion, depth = 2, device = device)\n",
    "model = model.cuda()\n",
    "\n",
    "student  = FCRNA.FCRN_A(criterion_stud, input_filters=3, filters=64, N=2)\n",
    "student = student.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.025, momentum=0.9, weight_decay=3e-4)\n",
    "optimizer_stud =  torch.optim.SGD(student.parameters(), 0.025, momentum=0.9, weight_decay=3e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, float(epochs))\n",
    "\n",
    "architect = architect.Architect(model, student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import data_loader\n",
    "from base import train\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "data_loader = train.get_loader('cell', batch_size=1)\n",
    "data_loader_unlabeled = train.get_loader('cell', batch_size=1)\n",
    "\n",
    "train_queue = data_loader['train']\n",
    "valid_queue = data_loader['valid']\n",
    "unlabeled_queue = data_loader_unlabeled['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cusloss(inp,tar):\n",
    "    m = nn.Softmax(-1)\n",
    "    lm = nn.LogSoftmax(-1)\n",
    "    lenn = inp.shape[0]\n",
    "    inp = lm(inp)\n",
    "    tar = m(tar)\n",
    "    out = inp*tar\n",
    "    ll = (out.sum()*(-1))/lenn\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_queue, valid_queue, unlabeled_queue, model, student, architect, criterion, criterion_stud, optimizer, optimizer_stud, lr):\n",
    "    \n",
    "    true_values = []\n",
    "    predicted_values = []\n",
    "    \n",
    "    for image, target in tqdm(train_queue):\n",
    "        model.train()\n",
    "\n",
    "        image = Variable(image, requires_grad=False).cuda()\n",
    "        target = Variable(target, requires_grad=False).cuda()\n",
    "\n",
    "        # get a random minibatch from the search queue with replacement\n",
    "        input_search, target_search = next(iter(valid_queue))\n",
    "        input_search = Variable(input_search, requires_grad=True).cuda()\n",
    "        target_search = Variable(target_search, requires_grad=True).cuda()\n",
    "\n",
    "        # get a random minibatch from the cifar-100 queue with replacement\n",
    "        input_unlabeled, target_unlabeled = next(iter(unlabeled_queue))\n",
    "        input_unlabeled = Variable(input_unlabeled, requires_grad=True).cuda()\n",
    "        target_unlabeled = Variable(target_unlabeled, requires_grad=True).cuda()\n",
    "\n",
    "        architect.step(image, target, input_search, target_search, input_unlabeled, lr, optimizer, unrolled=True)\n",
    "        architect.step1(image, target, input_search, target_search, input_unlabeled, lr, optimizer, optimizer_stud, unrolled=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(image)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer_stud.zero_grad()\n",
    "        l1 = model(input_unlabeled)\n",
    "        logits1 = student(input_unlabeled)\n",
    "        loss1 = cusloss(logits1, l1.detach())\n",
    "\n",
    "\n",
    "        loss1.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), 5)\n",
    "\n",
    "        #nn.utils.clip_grad_norm(student.parameters(), args.grad_clip)\n",
    "        optimizer_stud.step()\n",
    "\n",
    "        optimizer_stud.zero_grad()\n",
    "        logits2 = student(image)\n",
    "        loss2 = criterion_stud(logits2, target)\n",
    "\n",
    "        loss2.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), 5)\n",
    "\n",
    "        #nn.utils.clip_grad_norm(student.parameters(), args.grad_clip)\n",
    "        optimizer_stud.step()\n",
    "        \n",
    "        for true, predicted in zip(target, logits):\n",
    "\n",
    "            true_counts = torch.sum(true).item() / 100\n",
    "            predicted_counts = torch.sum(predicted).item() / 100\n",
    "\n",
    "            # update current epoch results\n",
    "            true_values.append(true_counts)\n",
    "            predicted_values.append(predicted_counts)\n",
    "        \n",
    "    plot(true_values, predicted_values)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hicks\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "C:\\Users\\hicks\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:508: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9821dc01cc4b3d8c87378275e97bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hicks\\Desktop\\ECE\\269\\project_code\\lbt\\architect.py:82: UserWarning: This overload of sub is deprecated:\n",
      "\tsub(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tsub(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1005.)\n",
      "  unrolled_model = self._construct_model_from_theta(theta.sub(eta, moment+dtheta))\n",
      "<ipython-input-7-d4c823287aba>:30: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), 5)\n",
      "<ipython-input-7-d4c823287aba>:40: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), 5)\n",
      "<ipython-input-7-d4c823287aba>:50: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), 5)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    \n",
    "    scheduler.step()\n",
    "    lr = scheduler.get_lr()[0]\n",
    "    \n",
    "    train(train_queue, valid_queue, unlabeled_queue, model, student, architect, criterion, criterion_stud, optimizer, optimizer_stud, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
